{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f61fb0-4be2-4e00-a768-aa49e9494546",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95661875-649a-4bfe-8914-d10dd498fc42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "385/385 [==============================] - 4s 5ms/step - loss: 1.0817 - accuracy: 0.6136 - val_loss: 0.9019 - val_accuracy: 0.6284\n",
      "Epoch 2/50\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.7786 - accuracy: 0.6460 - val_loss: 0.7073 - val_accuracy: 0.6544\n",
      "Epoch 3/50\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.6832 - accuracy: 0.6528 - val_loss: 0.6542 - val_accuracy: 0.6537\n",
      "Epoch 4/50\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.6475 - accuracy: 0.6574 - val_loss: 0.6353 - val_accuracy: 0.6561\n",
      "Epoch 5/50\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.6367 - accuracy: 0.6577 - val_loss: 0.6296 - val_accuracy: 0.6578\n",
      "Epoch 6/50\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.6347 - accuracy: 0.6617 - val_loss: 0.6266 - val_accuracy: 0.6639\n",
      "Epoch 7/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.6343 - accuracy: 0.6585 - val_loss: 0.6244 - val_accuracy: 0.6595\n",
      "Epoch 8/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.6302 - accuracy: 0.6601 - val_loss: 0.6214 - val_accuracy: 0.6622\n",
      "Epoch 9/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.6297 - accuracy: 0.6659 - val_loss: 0.6184 - val_accuracy: 0.6667\n",
      "Epoch 10/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.6252 - accuracy: 0.6638 - val_loss: 0.6230 - val_accuracy: 0.6663\n",
      "Epoch 11/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.6251 - accuracy: 0.6673 - val_loss: 0.6165 - val_accuracy: 0.6704\n",
      "Epoch 12/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.6185 - accuracy: 0.6734 - val_loss: 0.6148 - val_accuracy: 0.6858\n",
      "Epoch 13/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.6173 - accuracy: 0.6728 - val_loss: 0.6298 - val_accuracy: 0.6701\n",
      "Epoch 14/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.6151 - accuracy: 0.6738 - val_loss: 0.6108 - val_accuracy: 0.6940\n",
      "Epoch 15/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.6095 - accuracy: 0.6822 - val_loss: 0.6187 - val_accuracy: 0.6961\n",
      "Epoch 16/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.6073 - accuracy: 0.6819 - val_loss: 0.6289 - val_accuracy: 0.6988\n",
      "Epoch 17/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.6024 - accuracy: 0.6866 - val_loss: 0.6247 - val_accuracy: 0.7026\n",
      "Epoch 18/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.6015 - accuracy: 0.6845 - val_loss: 0.6278 - val_accuracy: 0.6964\n",
      "Epoch 19/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.6017 - accuracy: 0.6860 - val_loss: 0.6247 - val_accuracy: 0.7039\n",
      "Epoch 20/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.5973 - accuracy: 0.6955 - val_loss: 0.6191 - val_accuracy: 0.7080\n",
      "Epoch 21/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.5969 - accuracy: 0.6929 - val_loss: 0.6344 - val_accuracy: 0.6913\n",
      "Epoch 22/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.5973 - accuracy: 0.6892 - val_loss: 0.6209 - val_accuracy: 0.6848\n",
      "Epoch 23/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.5974 - accuracy: 0.6902 - val_loss: 0.6204 - val_accuracy: 0.6926\n",
      "Epoch 24/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.5975 - accuracy: 0.6889 - val_loss: 0.6014 - val_accuracy: 0.7132\n",
      "Epoch 25/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.5962 - accuracy: 0.6926 - val_loss: 0.6216 - val_accuracy: 0.6988\n",
      "Epoch 26/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.5924 - accuracy: 0.6959 - val_loss: 0.6052 - val_accuracy: 0.7121\n",
      "Epoch 27/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.5923 - accuracy: 0.6948 - val_loss: 0.6177 - val_accuracy: 0.6964\n",
      "Epoch 28/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.5917 - accuracy: 0.6937 - val_loss: 0.6065 - val_accuracy: 0.7015\n",
      "Epoch 29/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.5921 - accuracy: 0.6939 - val_loss: 0.6069 - val_accuracy: 0.7091\n",
      "Epoch 30/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.5913 - accuracy: 0.6965 - val_loss: 0.6172 - val_accuracy: 0.6916\n",
      "Epoch 31/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.5936 - accuracy: 0.6954 - val_loss: 0.6052 - val_accuracy: 0.7056\n",
      "Epoch 32/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.5914 - accuracy: 0.6965 - val_loss: 0.5907 - val_accuracy: 0.7108\n",
      "Epoch 33/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.5930 - accuracy: 0.6948 - val_loss: 0.6206 - val_accuracy: 0.6803\n",
      "Epoch 34/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.5893 - accuracy: 0.6973 - val_loss: 0.6116 - val_accuracy: 0.7022\n",
      "Epoch 35/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.5865 - accuracy: 0.6971 - val_loss: 0.6012 - val_accuracy: 0.7132\n",
      "Epoch 36/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.5925 - accuracy: 0.6940 - val_loss: 0.5968 - val_accuracy: 0.7101\n",
      "Epoch 37/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.5902 - accuracy: 0.6954 - val_loss: 0.6058 - val_accuracy: 0.6981\n",
      "Epoch 38/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.5894 - accuracy: 0.6978 - val_loss: 0.6023 - val_accuracy: 0.7091\n",
      "Epoch 39/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.5909 - accuracy: 0.6967 - val_loss: 0.6025 - val_accuracy: 0.7056\n",
      "Epoch 40/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.5895 - accuracy: 0.6994 - val_loss: 0.5943 - val_accuracy: 0.7097\n",
      "Epoch 41/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.5894 - accuracy: 0.6990 - val_loss: 0.6001 - val_accuracy: 0.7084\n",
      "Epoch 42/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.5910 - accuracy: 0.6957 - val_loss: 0.5941 - val_accuracy: 0.7074\n",
      "Epoch 43/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.5909 - accuracy: 0.6952 - val_loss: 0.6056 - val_accuracy: 0.7101\n",
      "Epoch 44/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.5891 - accuracy: 0.7030 - val_loss: 0.5971 - val_accuracy: 0.7087\n",
      "Epoch 45/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.5871 - accuracy: 0.7014 - val_loss: 0.5936 - val_accuracy: 0.7149\n",
      "Epoch 46/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.5873 - accuracy: 0.7004 - val_loss: 0.5852 - val_accuracy: 0.7063\n",
      "Epoch 47/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.5879 - accuracy: 0.7041 - val_loss: 0.6008 - val_accuracy: 0.7002\n",
      "Epoch 48/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.5893 - accuracy: 0.6991 - val_loss: 0.5896 - val_accuracy: 0.7128\n",
      "Epoch 49/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.5875 - accuracy: 0.7001 - val_loss: 0.5921 - val_accuracy: 0.7145\n",
      "Epoch 50/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.5869 - accuracy: 0.6983 - val_loss: 0.5986 - val_accuracy: 0.7118\n",
      "92/92 [==============================] - 0s 1ms/step\n",
      "Precision: 0.68\n",
      "Recall: 0.78\n",
      "F1 Score: 0.73\n",
      "Accuracy: 71.18%\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import pytz\n",
    "from dateutil import parser\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "def parse_tweet_file(file_path, start_date, end_date):\n",
    "    tweets = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                tweet_data = json.loads(line)\n",
    "                tweet_text = \" \".join(tweet_data['text']) if isinstance(tweet_data['text'], list) else tweet_data['text']\n",
    "                tweet_time = parser.parse(tweet_data['created_at'])\n",
    "                tweet_time = tweet_time.astimezone(pytz.timezone('US/Eastern'))\n",
    "                date_key = tweet_time.date()\n",
    "                if start_date <= date_key <= end_date:\n",
    "                    tweets.append((tweet_text, date_key))\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "    return tweets\n",
    "\n",
    "def parse_price_file(file_path, start_date, end_date):\n",
    "    prices = {}\n",
    "    volumes = {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            fields = line.strip().split('\\t')\n",
    "            if len(fields) < 6:\n",
    "                continue\n",
    "            date_str = fields[0]\n",
    "            try:\n",
    "                price_time = datetime.datetime.strptime(date_str, '%Y-%m-%d')\n",
    "                date_key = price_time.date()\n",
    "                if start_date <= date_key <= end_date:\n",
    "                    close_price_str = fields[4]\n",
    "                    volume_str = fields[5]\n",
    "                    close_price = float(close_price_str)\n",
    "                    volume = float(volume_str)\n",
    "                    prices[date_key] = close_price\n",
    "                    volumes[date_key] = volume\n",
    "            except ValueError:\n",
    "                continue\n",
    "    return prices, volumes\n",
    "\n",
    "def load_data_with_sentiment(tweet_root_dir, price_root_dir, start_date, end_date, tickers):\n",
    "    sentiments = []\n",
    "    labels = []\n",
    "    sentiment_changes = []\n",
    "    price_changes = []\n",
    "    moving_averages = []\n",
    "    volumes = []\n",
    "    days_of_week = []\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "    for ticker in tickers:\n",
    "        tweet_dir = os.path.join(tweet_root_dir, ticker)\n",
    "        price_file = os.path.join(price_root_dir, f\"{ticker}.txt\")\n",
    "\n",
    "        if not os.path.isdir(tweet_dir) or not os.path.isfile(price_file):\n",
    "            continue\n",
    "\n",
    "        ticker_prices, ticker_volumes = parse_price_file(price_file, start_date, end_date)\n",
    "        if not ticker_prices:\n",
    "            continue\n",
    "\n",
    "        tweets_by_date = {}\n",
    "        for file in os.listdir(tweet_dir):\n",
    "            file_path = os.path.join(tweet_dir, file)\n",
    "            if os.path.isfile(file_path):\n",
    "                tweets_with_dates = parse_tweet_file(file_path, start_date, end_date)\n",
    "                for tweet_text, date_key in tweets_with_dates:\n",
    "                    if date_key not in tweets_by_date:\n",
    "                        tweets_by_date[date_key] = []\n",
    "                    tweets_by_date[date_key].append(tweet_text)\n",
    "        if not tweets_by_date:\n",
    "            continue\n",
    "\n",
    "        daily_sentiments = {}\n",
    "        for date, tweets in tweets_by_date.items():\n",
    "            daily_compound_scores = [sia.polarity_scores(tweet)['compound'] for tweet in tweets]\n",
    "            if daily_compound_scores:\n",
    "                daily_sentiments[date] = np.mean(daily_compound_scores)\n",
    "\n",
    "        sorted_dates = sorted(ticker_prices.keys())\n",
    "        prev_sentiment = None\n",
    "        prev_price = None\n",
    "        moving_avg_window = 5\n",
    "        for i, date_today in enumerate(sorted_dates[:-1]):\n",
    "            date_tomorrow = sorted_dates[i + 1]\n",
    "            if date_today in daily_sentiments and date_today in ticker_prices:\n",
    "                # Use features up to date_today to predict price movement on date_tomorrow\n",
    "                sentiment_score = daily_sentiments[date_today]\n",
    "                price_today = ticker_prices[date_today]\n",
    "                volume_today = ticker_volumes[date_today]\n",
    "                \n",
    "                # Label is based on price change from date_today to date_tomorrow\n",
    "                price_tomorrow = ticker_prices[date_tomorrow]\n",
    "                label = 1 if price_tomorrow > price_today else 0\n",
    "                \n",
    "                # Features should not use data from date_tomorrow or later\n",
    "                if i >= moving_avg_window:\n",
    "                    moving_avg = np.mean([ticker_prices[sorted_dates[j]] for j in range(i - moving_avg_window, i)])\n",
    "                else:\n",
    "                    moving_avg = np.mean([ticker_prices[sorted_dates[j]] for j in range(i)])\n",
    "\n",
    "                next_day = date_today + datetime.timedelta(days=1)\n",
    "                if next_day in ticker_prices:\n",
    "                    price_next = ticker_prices[next_day]\n",
    "                    price_diff = price_next - price_today\n",
    "                    label = 1 if price_diff > 0 else 0\n",
    "                    sentiment_change = sentiment_score - prev_sentiment if prev_sentiment is not None else 0\n",
    "                    price_change = price_today - prev_price if prev_price is not None else 0\n",
    "                    moving_avg = np.mean([ticker_prices[sorted_dates[j]] for j in range(max(0, i - moving_avg_window + 1), i + 1)])\n",
    "                    day_of_week = date_today.weekday()\n",
    "\n",
    "                    sentiments.append(sentiment_score)\n",
    "                    sentiment_changes.append(sentiment_change)\n",
    "                    price_changes.append(price_change)\n",
    "                    moving_averages.append(moving_avg)\n",
    "                    volumes.append(volume_today)\n",
    "                    days_of_week.append(day_of_week)\n",
    "                    labels.append(label)\n",
    "\n",
    "                    prev_sentiment = sentiment_score\n",
    "                    prev_price = price_today\n",
    "\n",
    "    return sentiments, sentiment_changes, price_changes, moving_averages, volumes, days_of_week, labels\n",
    "\n",
    "\n",
    "\n",
    "tweet_root_dir = '/home/sigurds/ikt450/Project/Data/stocknet-dataset-master/tweet/preprocessed/'\n",
    "price_root_dir = '/home/sigurds/ikt450/Project/Data/stocknet-dataset-master/price/preprocessed/'\n",
    "\"\"\"\n",
    "# Define new date ranges\n",
    "train_start_date = datetime.date(2014, 1, 1)\n",
    "train_end_date = datetime.date(2015, 6, 30)\n",
    "test_start_date = datetime.date(2015, 7, 1)\n",
    "test_end_date = datetime.date(2016, 1, 1)\n",
    "\"\"\"\n",
    "train_start_date = datetime.date(2014, 1, 1)\n",
    "train_end_date = datetime.date(2016, 1, 1)\n",
    "test_start_date = datetime.date(2014, 1, 1)\n",
    "test_end_date = datetime.date(2016, 1, 1)\n",
    "\n",
    "\n",
    "# Get all available tickers from the tweet data directory\n",
    "all_tickers = [ticker for ticker in os.listdir(tweet_root_dir) if os.path.isdir(os.path.join(tweet_root_dir, ticker))]\n",
    "\n",
    "# Split the tickers into training and testing sets with no overlap\n",
    "train_tickers, test_tickers = train_test_split(all_tickers, test_size=0.2, random_state=42)\n",
    "\n",
    "# Verify that there is no overlap between train_tickers and test_tickers\n",
    "assert set(train_tickers).isdisjoint(set(test_tickers)), \"Training and testing tickers overlap!\"\n",
    "\n",
    "# Load training data from train tickers\n",
    "(sentiments_train, sentiment_changes_train, price_changes_train,\n",
    " moving_averages_train, volumes_train, days_of_week_train, labels_train) = load_data_with_sentiment(\n",
    "    tweet_root_dir, price_root_dir, train_start_date, train_end_date, train_tickers)\n",
    "\n",
    "# Load testing data from test tickers\n",
    "(sentiments_test, sentiment_changes_test, price_changes_test,\n",
    " moving_averages_test, volumes_test, days_of_week_test, labels_test) = load_data_with_sentiment(\n",
    "    tweet_root_dir, price_root_dir, test_start_date, test_end_date, test_tickers)\n",
    "\n",
    "if not sentiments_train or not sentiments_test:\n",
    "    print(\"No data was loaded. Please check your data files and parsing functions.\")\n",
    "else:\n",
    "    # Convert lists to NumPy arrays\n",
    "    sentiments_train = np.array(sentiments_train)\n",
    "    sentiment_changes_train = np.array(sentiment_changes_train)\n",
    "    price_changes_train = np.array(price_changes_train)\n",
    "    moving_averages_train = np.array(moving_averages_train)\n",
    "    volumes_train = np.array(volumes_train)\n",
    "    days_of_week_train = np.array(days_of_week_train)\n",
    "    labels_train = np.array(labels_train)\n",
    "\n",
    "    sentiments_test = np.array(sentiments_test)\n",
    "    sentiment_changes_test = np.array(sentiment_changes_test)\n",
    "    price_changes_test = np.array(price_changes_test)\n",
    "    moving_averages_test = np.array(moving_averages_test)\n",
    "    volumes_test = np.array(volumes_test)\n",
    "    days_of_week_test = np.array(days_of_week_test)\n",
    "    labels_test = np.array(labels_test)\n",
    "\n",
    "    # Stack features\n",
    "    x_train = np.column_stack((sentiments_train, sentiment_changes_train, price_changes_train,\n",
    "                               moving_averages_train, volumes_train, days_of_week_train))\n",
    "    x_test = np.column_stack((sentiments_test, sentiment_changes_test, price_changes_test,\n",
    "                              moving_averages_test, volumes_test, days_of_week_test))\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    x_train = scaler.fit_transform(x_train.reshape(-1, x_train.shape[-1])).reshape(x_train.shape)\n",
    "    x_test = scaler.transform(x_test.reshape(-1, x_test.shape[-1])).reshape(x_test.shape)\n",
    "\n",
    "    # Reshape data\n",
    "    x_train = x_train.reshape((x_train.shape[0], 1, x_train.shape[1]))\n",
    "    x_test = x_test.reshape((x_test.shape[0], 1, x_test.shape[1]))\n",
    "\n",
    "\n",
    "    # Create TensorFlow datasets\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((x_train, labels_train))\n",
    "    train_dataset = train_dataset.shuffle(1024).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((x_test, labels_test))\n",
    "    test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    # Build and compile the model\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(1, x_train.shape[2])),\n",
    "        layers.LSTM(64, return_sequences=False),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(16, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "history = model.fit(train_dataset, epochs=50, validation_data=test_dataset)\n",
    "\n",
    "# Evaluate model on test data\n",
    "y_pred_prob = model.predict(x_test).flatten()\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "precision = precision_score(labels_test, y_pred)\n",
    "recall = recall_score(labels_test, y_pred)\n",
    "f1 = f1_score(labels_test, y_pred)\n",
    "accuracy = accuracy_score(labels_test, y_pred)\n",
    "\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Plotting test accuracy over epochs\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig('LSTM_Graph_acc_FULLDATE2input.pdf', format='pdf', bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8522562f-3cee-4e3f-82d1-2eb571c69798",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a9a98f6-00ee-4b44-9ceb-d843c7fe12a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-05 08:53:19.296198: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "385/385 [==============================] - 6s 6ms/step - loss: 1.0724 - accuracy: 0.6032 - val_loss: 0.8765 - val_accuracy: 0.6591\n",
      "Epoch 2/150\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.7725 - accuracy: 0.6445 - val_loss: 0.7017 - val_accuracy: 0.6544\n",
      "Epoch 3/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.6796 - accuracy: 0.6535 - val_loss: 0.6529 - val_accuracy: 0.6554\n",
      "Epoch 4/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.6466 - accuracy: 0.6581 - val_loss: 0.6377 - val_accuracy: 0.6564\n",
      "Epoch 5/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.6385 - accuracy: 0.6546 - val_loss: 0.6301 - val_accuracy: 0.6591\n",
      "Epoch 6/150\n",
      "385/385 [==============================] - 3s 7ms/step - loss: 0.6334 - accuracy: 0.6584 - val_loss: 0.6265 - val_accuracy: 0.6561\n",
      "Epoch 7/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.6325 - accuracy: 0.6605 - val_loss: 0.6297 - val_accuracy: 0.6571\n",
      "Epoch 8/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.6319 - accuracy: 0.6620 - val_loss: 0.6225 - val_accuracy: 0.6680\n",
      "Epoch 9/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.6286 - accuracy: 0.6631 - val_loss: 0.6227 - val_accuracy: 0.6643\n",
      "Epoch 10/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.6274 - accuracy: 0.6601 - val_loss: 0.6191 - val_accuracy: 0.6718\n",
      "Epoch 11/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.6266 - accuracy: 0.6680 - val_loss: 0.6147 - val_accuracy: 0.6756\n",
      "Epoch 12/150\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.6226 - accuracy: 0.6687 - val_loss: 0.6157 - val_accuracy: 0.6769\n",
      "Epoch 13/150\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.6204 - accuracy: 0.6698 - val_loss: 0.6179 - val_accuracy: 0.6803\n",
      "Epoch 14/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.6151 - accuracy: 0.6776 - val_loss: 0.6225 - val_accuracy: 0.6899\n",
      "Epoch 15/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.6085 - accuracy: 0.6803 - val_loss: 0.6230 - val_accuracy: 0.6961\n",
      "Epoch 16/150\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.6083 - accuracy: 0.6791 - val_loss: 0.6332 - val_accuracy: 0.6896\n",
      "Epoch 17/150\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.6065 - accuracy: 0.6843 - val_loss: 0.6285 - val_accuracy: 0.7063\n",
      "Epoch 18/150\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.6048 - accuracy: 0.6893 - val_loss: 0.6136 - val_accuracy: 0.7050\n",
      "Epoch 19/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.6032 - accuracy: 0.6874 - val_loss: 0.6201 - val_accuracy: 0.6985\n",
      "Epoch 20/150\n",
      "385/385 [==============================] - 3s 6ms/step - loss: 0.6024 - accuracy: 0.6906 - val_loss: 0.6273 - val_accuracy: 0.7097\n",
      "Epoch 21/150\n",
      "385/385 [==============================] - 2s 6ms/step - loss: 0.6002 - accuracy: 0.6864 - val_loss: 0.6184 - val_accuracy: 0.7084\n",
      "Epoch 22/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5993 - accuracy: 0.6944 - val_loss: 0.6248 - val_accuracy: 0.7015\n",
      "Epoch 23/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5982 - accuracy: 0.6933 - val_loss: 0.6159 - val_accuracy: 0.7091\n",
      "Epoch 24/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.6000 - accuracy: 0.6922 - val_loss: 0.6160 - val_accuracy: 0.7060\n",
      "Epoch 25/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5971 - accuracy: 0.6933 - val_loss: 0.6296 - val_accuracy: 0.6930\n",
      "Epoch 26/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5971 - accuracy: 0.6940 - val_loss: 0.6140 - val_accuracy: 0.7056\n",
      "Epoch 27/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5960 - accuracy: 0.6932 - val_loss: 0.6229 - val_accuracy: 0.7009\n",
      "Epoch 28/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5963 - accuracy: 0.6912 - val_loss: 0.6163 - val_accuracy: 0.7111\n",
      "Epoch 29/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5922 - accuracy: 0.6961 - val_loss: 0.6112 - val_accuracy: 0.7063\n",
      "Epoch 30/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5953 - accuracy: 0.6931 - val_loss: 0.6031 - val_accuracy: 0.7032\n",
      "Epoch 31/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5948 - accuracy: 0.6935 - val_loss: 0.6205 - val_accuracy: 0.7036\n",
      "Epoch 32/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5930 - accuracy: 0.6939 - val_loss: 0.6122 - val_accuracy: 0.7145\n",
      "Epoch 33/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5925 - accuracy: 0.6991 - val_loss: 0.5993 - val_accuracy: 0.7111\n",
      "Epoch 34/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5915 - accuracy: 0.6993 - val_loss: 0.6121 - val_accuracy: 0.7039\n",
      "Epoch 35/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5916 - accuracy: 0.7017 - val_loss: 0.5993 - val_accuracy: 0.7104\n",
      "Epoch 36/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5925 - accuracy: 0.6955 - val_loss: 0.6034 - val_accuracy: 0.7091\n",
      "Epoch 37/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5891 - accuracy: 0.7008 - val_loss: 0.6273 - val_accuracy: 0.7005\n",
      "Epoch 38/150\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.5931 - accuracy: 0.6961 - val_loss: 0.6004 - val_accuracy: 0.7101\n",
      "Epoch 39/150\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.5910 - accuracy: 0.6975 - val_loss: 0.6113 - val_accuracy: 0.7077\n",
      "Epoch 40/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5881 - accuracy: 0.7026 - val_loss: 0.5989 - val_accuracy: 0.7138\n",
      "Epoch 41/150\n",
      "385/385 [==============================] - 2s 6ms/step - loss: 0.5906 - accuracy: 0.6970 - val_loss: 0.6159 - val_accuracy: 0.6981\n",
      "Epoch 42/150\n",
      "385/385 [==============================] - 3s 7ms/step - loss: 0.5898 - accuracy: 0.7004 - val_loss: 0.5912 - val_accuracy: 0.7156\n",
      "Epoch 43/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5902 - accuracy: 0.6996 - val_loss: 0.5980 - val_accuracy: 0.7009\n",
      "Epoch 44/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5900 - accuracy: 0.6948 - val_loss: 0.6010 - val_accuracy: 0.7084\n",
      "Epoch 45/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5895 - accuracy: 0.6982 - val_loss: 0.6022 - val_accuracy: 0.6985\n",
      "Epoch 46/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5888 - accuracy: 0.7035 - val_loss: 0.5967 - val_accuracy: 0.7104\n",
      "Epoch 47/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5872 - accuracy: 0.6987 - val_loss: 0.6030 - val_accuracy: 0.7104\n",
      "Epoch 48/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5877 - accuracy: 0.6991 - val_loss: 0.6088 - val_accuracy: 0.7015\n",
      "Epoch 49/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5869 - accuracy: 0.6979 - val_loss: 0.6024 - val_accuracy: 0.7125\n",
      "Epoch 50/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5880 - accuracy: 0.6983 - val_loss: 0.5993 - val_accuracy: 0.7060\n",
      "Epoch 51/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5872 - accuracy: 0.7000 - val_loss: 0.6087 - val_accuracy: 0.7019\n",
      "Epoch 52/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5891 - accuracy: 0.7021 - val_loss: 0.6041 - val_accuracy: 0.6964\n",
      "Epoch 53/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5868 - accuracy: 0.7023 - val_loss: 0.5990 - val_accuracy: 0.7074\n",
      "Epoch 54/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5857 - accuracy: 0.6977 - val_loss: 0.5967 - val_accuracy: 0.7128\n",
      "Epoch 55/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5881 - accuracy: 0.7032 - val_loss: 0.5972 - val_accuracy: 0.7050\n",
      "Epoch 56/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5876 - accuracy: 0.7006 - val_loss: 0.5959 - val_accuracy: 0.7135\n",
      "Epoch 57/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5871 - accuracy: 0.6983 - val_loss: 0.6122 - val_accuracy: 0.6957\n",
      "Epoch 58/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5885 - accuracy: 0.7004 - val_loss: 0.5929 - val_accuracy: 0.7142\n",
      "Epoch 59/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5860 - accuracy: 0.7022 - val_loss: 0.5959 - val_accuracy: 0.7022\n",
      "Epoch 60/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5883 - accuracy: 0.6975 - val_loss: 0.5849 - val_accuracy: 0.7115\n",
      "Epoch 61/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5869 - accuracy: 0.7003 - val_loss: 0.5933 - val_accuracy: 0.7125\n",
      "Epoch 62/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5890 - accuracy: 0.6972 - val_loss: 0.5968 - val_accuracy: 0.7128\n",
      "Epoch 63/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5869 - accuracy: 0.7003 - val_loss: 0.5902 - val_accuracy: 0.7039\n",
      "Epoch 64/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5887 - accuracy: 0.6999 - val_loss: 0.5974 - val_accuracy: 0.7152\n",
      "Epoch 65/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5848 - accuracy: 0.7042 - val_loss: 0.5872 - val_accuracy: 0.7128\n",
      "Epoch 66/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5881 - accuracy: 0.6985 - val_loss: 0.5895 - val_accuracy: 0.7097\n",
      "Epoch 67/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5852 - accuracy: 0.7073 - val_loss: 0.6009 - val_accuracy: 0.7005\n",
      "Epoch 68/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5873 - accuracy: 0.7039 - val_loss: 0.6013 - val_accuracy: 0.7084\n",
      "Epoch 69/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5850 - accuracy: 0.6987 - val_loss: 0.5874 - val_accuracy: 0.7050\n",
      "Epoch 70/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5863 - accuracy: 0.6994 - val_loss: 0.5904 - val_accuracy: 0.7084\n",
      "Epoch 71/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5868 - accuracy: 0.6987 - val_loss: 0.5871 - val_accuracy: 0.7070\n",
      "Epoch 72/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5863 - accuracy: 0.6986 - val_loss: 0.5865 - val_accuracy: 0.7128\n",
      "Epoch 73/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5862 - accuracy: 0.7021 - val_loss: 0.5771 - val_accuracy: 0.7128\n",
      "Epoch 74/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5863 - accuracy: 0.7005 - val_loss: 0.5925 - val_accuracy: 0.7121\n",
      "Epoch 75/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5865 - accuracy: 0.7005 - val_loss: 0.5938 - val_accuracy: 0.7074\n",
      "Epoch 76/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5856 - accuracy: 0.7039 - val_loss: 0.5833 - val_accuracy: 0.7152\n",
      "Epoch 77/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5854 - accuracy: 0.7012 - val_loss: 0.5941 - val_accuracy: 0.7097\n",
      "Epoch 78/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5862 - accuracy: 0.7017 - val_loss: 0.6043 - val_accuracy: 0.7145\n",
      "Epoch 79/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5864 - accuracy: 0.7016 - val_loss: 0.5929 - val_accuracy: 0.7074\n",
      "Epoch 80/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5878 - accuracy: 0.7002 - val_loss: 0.5821 - val_accuracy: 0.7132\n",
      "Epoch 81/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5836 - accuracy: 0.7033 - val_loss: 0.6033 - val_accuracy: 0.7009\n",
      "Epoch 82/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5821 - accuracy: 0.7020 - val_loss: 0.5832 - val_accuracy: 0.7097\n",
      "Epoch 83/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5859 - accuracy: 0.7052 - val_loss: 0.5803 - val_accuracy: 0.7132\n",
      "Epoch 84/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5865 - accuracy: 0.7039 - val_loss: 0.5986 - val_accuracy: 0.7108\n",
      "Epoch 85/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5862 - accuracy: 0.7009 - val_loss: 0.5810 - val_accuracy: 0.7101\n",
      "Epoch 86/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5857 - accuracy: 0.7013 - val_loss: 0.5966 - val_accuracy: 0.7087\n",
      "Epoch 87/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5846 - accuracy: 0.7063 - val_loss: 0.5966 - val_accuracy: 0.7091\n",
      "Epoch 88/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5860 - accuracy: 0.7035 - val_loss: 0.5843 - val_accuracy: 0.7149\n",
      "Epoch 89/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5866 - accuracy: 0.7037 - val_loss: 0.5905 - val_accuracy: 0.7115\n",
      "Epoch 90/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5848 - accuracy: 0.7011 - val_loss: 0.5839 - val_accuracy: 0.7121\n",
      "Epoch 91/150\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.5865 - accuracy: 0.6999 - val_loss: 0.5850 - val_accuracy: 0.7118\n",
      "Epoch 92/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5874 - accuracy: 0.7003 - val_loss: 0.5795 - val_accuracy: 0.7077\n",
      "Epoch 93/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5847 - accuracy: 0.7043 - val_loss: 0.5819 - val_accuracy: 0.7128\n",
      "Epoch 94/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5851 - accuracy: 0.7017 - val_loss: 0.5818 - val_accuracy: 0.7138\n",
      "Epoch 95/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5878 - accuracy: 0.7053 - val_loss: 0.5799 - val_accuracy: 0.7142\n",
      "Epoch 96/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5833 - accuracy: 0.7026 - val_loss: 0.5984 - val_accuracy: 0.7039\n",
      "Epoch 97/150\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5836 - accuracy: 0.7037 - val_loss: 0.5965 - val_accuracy: 0.7108\n",
      "Epoch 98/150\n",
      "249/385 [==================>...........] - ETA: 0s - loss: 0.5862 - accuracy: 0.7075"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 240\u001b[0m\n\u001b[1;32m    221\u001b[0m     model \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[1;32m    222\u001b[0m         layers\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, x_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m])),\n\u001b[1;32m    223\u001b[0m         layers\u001b[38;5;241m.\u001b[39mGRU(\u001b[38;5;241m64\u001b[39m, return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m         layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    231\u001b[0m     ])\n\u001b[1;32m    233\u001b[0m     model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m),\n\u001b[1;32m    234\u001b[0m                   loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    235\u001b[0m                   metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 240\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;66;03m# Evaluate model on test data\u001b[39;00m\n\u001b[1;32m    243\u001b[0m y_pred_prob \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(x_test)\u001b[38;5;241m.\u001b[39mflatten()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import pytz\n",
    "from dateutil import parser\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "def parse_tweet_file(file_path, start_date, end_date):\n",
    "    tweets = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                tweet_data = json.loads(line)\n",
    "                tweet_text = \" \".join(tweet_data['text']) if isinstance(tweet_data['text'], list) else tweet_data['text']\n",
    "                tweet_time = parser.parse(tweet_data['created_at'])\n",
    "                tweet_time = tweet_time.astimezone(pytz.timezone('US/Eastern'))\n",
    "                date_key = tweet_time.date()\n",
    "                if start_date <= date_key <= end_date:\n",
    "                    tweets.append((tweet_text, date_key))\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "    return tweets\n",
    "\n",
    "def parse_price_file(file_path, start_date, end_date):\n",
    "    prices = {}\n",
    "    volumes = {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            fields = line.strip().split('\\t')\n",
    "            if len(fields) < 6:\n",
    "                continue\n",
    "            date_str = fields[0]\n",
    "            try:\n",
    "                price_time = datetime.datetime.strptime(date_str, '%Y-%m-%d')\n",
    "                date_key = price_time.date()\n",
    "                if start_date <= date_key <= end_date:\n",
    "                    close_price_str = fields[4]\n",
    "                    volume_str = fields[5]\n",
    "                    close_price = float(close_price_str)\n",
    "                    volume = float(volume_str)\n",
    "                    prices[date_key] = close_price\n",
    "                    volumes[date_key] = volume\n",
    "            except ValueError:\n",
    "                continue\n",
    "    return prices, volumes\n",
    "\n",
    "def load_data_with_sentiment(tweet_root_dir, price_root_dir, start_date, end_date, tickers):\n",
    "    sentiments = []\n",
    "    labels = []\n",
    "    sentiment_changes = []\n",
    "    price_changes = []\n",
    "    moving_averages = []\n",
    "    volumes = []\n",
    "    days_of_week = []\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "    for ticker in tickers:\n",
    "        tweet_dir = os.path.join(tweet_root_dir, ticker)\n",
    "        price_file = os.path.join(price_root_dir, f\"{ticker}.txt\")\n",
    "\n",
    "        if not os.path.isdir(tweet_dir) or not os.path.isfile(price_file):\n",
    "            continue\n",
    "\n",
    "        ticker_prices, ticker_volumes = parse_price_file(price_file, start_date, end_date)\n",
    "        if not ticker_prices:\n",
    "            continue\n",
    "\n",
    "        tweets_by_date = {}\n",
    "        for file in os.listdir(tweet_dir):\n",
    "            file_path = os.path.join(tweet_dir, file)\n",
    "            if os.path.isfile(file_path):\n",
    "                tweets_with_dates = parse_tweet_file(file_path, start_date, end_date)\n",
    "                for tweet_text, date_key in tweets_with_dates:\n",
    "                    if date_key not in tweets_by_date:\n",
    "                        tweets_by_date[date_key] = []\n",
    "                    tweets_by_date[date_key].append(tweet_text)\n",
    "        if not tweets_by_date:\n",
    "            continue\n",
    "\n",
    "        daily_sentiments = {}\n",
    "        for date, tweets in tweets_by_date.items():\n",
    "            daily_compound_scores = [sia.polarity_scores(tweet)['compound'] for tweet in tweets]\n",
    "            if daily_compound_scores:\n",
    "                daily_sentiments[date] = np.mean(daily_compound_scores)\n",
    "\n",
    "        sorted_dates = sorted(ticker_prices.keys())\n",
    "        prev_sentiment = None\n",
    "        prev_price = None\n",
    "        moving_avg_window = 5\n",
    "        for i, date_today in enumerate(sorted_dates[:-1]):\n",
    "            date_tomorrow = sorted_dates[i + 1]\n",
    "            if date_today in daily_sentiments and date_today in ticker_prices:\n",
    "                # Use features up to date_today to predict price movement on date_tomorrow\n",
    "                sentiment_score = daily_sentiments[date_today]\n",
    "                price_today = ticker_prices[date_today]\n",
    "                volume_today = ticker_volumes[date_today]\n",
    "                \n",
    "                # Label is based on price change from date_today to date_tomorrow\n",
    "                price_tomorrow = ticker_prices[date_tomorrow]\n",
    "                label = 1 if price_tomorrow > price_today else 0\n",
    "                \n",
    "                # Features should not use data from date_tomorrow or later\n",
    "                if i >= moving_avg_window:\n",
    "                    moving_avg = np.mean([ticker_prices[sorted_dates[j]] for j in range(i - moving_avg_window, i)])\n",
    "                else:\n",
    "                    moving_avg = np.mean([ticker_prices[sorted_dates[j]] for j in range(i)])\n",
    "\n",
    "                next_day = date_today + datetime.timedelta(days=1)\n",
    "                if next_day in ticker_prices:\n",
    "                    price_next = ticker_prices[next_day]\n",
    "                    price_diff = price_next - price_today\n",
    "                    label = 1 if price_diff > 0 else 0\n",
    "                    sentiment_change = sentiment_score - prev_sentiment if prev_sentiment is not None else 0\n",
    "                    price_change = price_today - prev_price if prev_price is not None else 0\n",
    "                    moving_avg = np.mean([ticker_prices[sorted_dates[j]] for j in range(max(0, i - moving_avg_window + 1), i + 1)])\n",
    "                    day_of_week = date_today.weekday()\n",
    "\n",
    "                    sentiments.append(sentiment_score)\n",
    "                    sentiment_changes.append(sentiment_change)\n",
    "                    price_changes.append(price_change)\n",
    "                    moving_averages.append(moving_avg)\n",
    "                    volumes.append(volume_today)\n",
    "                    days_of_week.append(day_of_week)\n",
    "                    labels.append(label)\n",
    "\n",
    "                    prev_sentiment = sentiment_score\n",
    "                    prev_price = price_today\n",
    "\n",
    "    return sentiments, sentiment_changes, price_changes, moving_averages, volumes, days_of_week, labels\n",
    "\n",
    "\n",
    "\n",
    "tweet_root_dir = '/home/sigurds/ikt450/Project/Data/stocknet-dataset-master/tweet/preprocessed/'\n",
    "price_root_dir = '/home/sigurds/ikt450/Project/Data/stocknet-dataset-master/price/preprocessed/'\n",
    "\"\"\"\n",
    "# Define new date ranges\n",
    "train_start_date = datetime.date(2014, 1, 1)\n",
    "train_end_date = datetime.date(2015, 6, 30)\n",
    "test_start_date = datetime.date(2015, 7, 1)\n",
    "test_end_date = datetime.date(2016, 1, 1)\n",
    "\"\"\"\n",
    "train_start_date = datetime.date(2014, 1, 1)\n",
    "train_end_date = datetime.date(2016, 1, 1)\n",
    "test_start_date = datetime.date(2014, 1, 1)\n",
    "test_end_date = datetime.date(2016, 1, 1)\n",
    "\n",
    "\n",
    "# Get all available tickers from the tweet data directory\n",
    "all_tickers = [ticker for ticker in os.listdir(tweet_root_dir) if os.path.isdir(os.path.join(tweet_root_dir, ticker))]\n",
    "\n",
    "# Split the tickers into training and testing sets with no overlap\n",
    "train_tickers, test_tickers = train_test_split(all_tickers, test_size=0.2, random_state=42)\n",
    "\n",
    "# Verify that there is no overlap between train_tickers and test_tickers\n",
    "assert set(train_tickers).isdisjoint(set(test_tickers)), \"Training and testing tickers overlap!\"\n",
    "\n",
    "# Load training data from train tickers\n",
    "(sentiments_train, sentiment_changes_train, price_changes_train,\n",
    " moving_averages_train, volumes_train, days_of_week_train, labels_train) = load_data_with_sentiment(\n",
    "    tweet_root_dir, price_root_dir, train_start_date, train_end_date, train_tickers)\n",
    "\n",
    "# Load testing data from test tickers\n",
    "(sentiments_test, sentiment_changes_test, price_changes_test,\n",
    " moving_averages_test, volumes_test, days_of_week_test, labels_test) = load_data_with_sentiment(\n",
    "    tweet_root_dir, price_root_dir, test_start_date, test_end_date, test_tickers)\n",
    "\n",
    "if not sentiments_train or not sentiments_test:\n",
    "    print(\"No data was loaded. Please check your data files and parsing functions.\")\n",
    "else:\n",
    "    # Convert lists to NumPy arrays\n",
    "    sentiments_train = np.array(sentiments_train)\n",
    "    sentiment_changes_train = np.array(sentiment_changes_train)\n",
    "    price_changes_train = np.array(price_changes_train)\n",
    "    moving_averages_train = np.array(moving_averages_train)\n",
    "    volumes_train = np.array(volumes_train)\n",
    "    days_of_week_train = np.array(days_of_week_train)\n",
    "    labels_train = np.array(labels_train)\n",
    "\n",
    "    sentiments_test = np.array(sentiments_test)\n",
    "    sentiment_changes_test = np.array(sentiment_changes_test)\n",
    "    price_changes_test = np.array(price_changes_test)\n",
    "    moving_averages_test = np.array(moving_averages_test)\n",
    "    volumes_test = np.array(volumes_test)\n",
    "    days_of_week_test = np.array(days_of_week_test)\n",
    "    labels_test = np.array(labels_test)\n",
    "\n",
    "    # Stack features\n",
    "    x_train = np.column_stack((sentiments_train, sentiment_changes_train, price_changes_train,\n",
    "                               moving_averages_train, volumes_train, days_of_week_train))\n",
    "    x_test = np.column_stack((sentiments_test, sentiment_changes_test, price_changes_test,\n",
    "                              moving_averages_test, volumes_test, days_of_week_test))\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    x_train = scaler.fit_transform(x_train.reshape(-1, x_train.shape[-1])).reshape(x_train.shape)\n",
    "    x_test = scaler.transform(x_test.reshape(-1, x_test.shape[-1])).reshape(x_test.shape)\n",
    "\n",
    "    # Reshape data\n",
    "    x_train = x_train.reshape((x_train.shape[0], 1, x_train.shape[1]))\n",
    "    x_test = x_test.reshape((x_test.shape[0], 1, x_test.shape[1]))\n",
    "\n",
    "\n",
    "    # Create TensorFlow datasets\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((x_train, labels_train))\n",
    "    train_dataset = train_dataset.shuffle(1024).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((x_test, labels_test))\n",
    "    test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    # Build and compile the model\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(1, x_train.shape[2])),\n",
    "        layers.GRU(64, return_sequences=False),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(16, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "history = model.fit(train_dataset, epochs=150, validation_data=test_dataset)\n",
    "\n",
    "# Evaluate model on test data\n",
    "y_pred_prob = model.predict(x_test).flatten()\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "precision = precision_score(labels_test, y_pred)\n",
    "recall = recall_score(labels_test, y_pred)\n",
    "f1 = f1_score(labels_test, y_pred)\n",
    "accuracy = accuracy_score(labels_test, y_pred)\n",
    "\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Plotting test accuracy over epochs\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b92f55f-742f-4c9f-aa4c-b2817d4df68c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad751c79-3cd3-4407-8342-4e8d8d921657",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d06881d-145e-44ad-899c-d14549593e74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sentiment_changes_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 190\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;66;03m# Convert lists to NumPy arrays\u001b[39;00m\n\u001b[1;32m    189\u001b[0m     sentiments_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(sentiments_train)\n\u001b[0;32m--> 190\u001b[0m     sentiment_changes_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43msentiment_changes_train\u001b[49m)\n\u001b[1;32m    191\u001b[0m     price_changes_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(price_changes_train)\n\u001b[1;32m    192\u001b[0m     moving_averages_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(moving_averages_train)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sentiment_changes_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import pytz\n",
    "from dateutil import parser\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "def parse_tweet_file(file_path, start_date, end_date):\n",
    "    tweets = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                tweet_data = json.loads(line)\n",
    "                tweet_text = \" \".join(tweet_data['text']) if isinstance(tweet_data['text'], list) else tweet_data['text']\n",
    "                tweet_time = parser.parse(tweet_data['created_at'])\n",
    "                tweet_time = tweet_time.astimezone(pytz.timezone('US/Eastern'))\n",
    "                date_key = tweet_time.date()\n",
    "                if start_date <= date_key <= end_date:\n",
    "                    tweets.append((tweet_text, date_key))\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "    return tweets\n",
    "\n",
    "\n",
    "def parse_price_file(file_path, start_date, end_date):\n",
    "    prices = {}\n",
    "    volumes = {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            fields = line.strip().split('\\t')\n",
    "            if len(fields) < 6:\n",
    "                continue\n",
    "            date_str = fields[0]\n",
    "            try:\n",
    "                price_time = datetime.datetime.strptime(date_str, '%Y-%m-%d')\n",
    "                date_key = price_time.date()\n",
    "                if start_date <= date_key <= end_date:\n",
    "                    close_price_str = fields[4]\n",
    "                    volume_str = fields[5]\n",
    "                    close_price = float(close_price_str)\n",
    "                    volume = float(volume_str)\n",
    "                    prices[date_key] = close_price\n",
    "                    volumes[date_key] = volume\n",
    "            except ValueError:\n",
    "                continue\n",
    "    return prices, volumes\n",
    "\n",
    "\n",
    "#function to load sentiments and process the information so RNN can get different features out of it.\n",
    "def load_data_with_sentiment(tweet_root_dir, price_root_dir, start_date, end_date, tickers):\n",
    "    sentiments = []\n",
    "    labels = []\n",
    "    sentiment_changes = []\n",
    "    price_changes = []\n",
    "    moving_averages = []\n",
    "    volumes = []\n",
    "    days_of_week = []\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "    for ticker in tickers:\n",
    "        tweet_dir = os.path.join(tweet_root_dir, ticker)\n",
    "        price_file = os.path.join(price_root_dir, f\"{ticker}.txt\")\n",
    "\n",
    "        if not os.path.isdir(tweet_dir) or not os.path.isfile(price_file):\n",
    "            continue\n",
    "\n",
    "        ticker_prices, ticker_volumes = parse_price_file(price_file, start_date, end_date)\n",
    "        if not ticker_prices:\n",
    "            continue\n",
    "\n",
    "        tweets_by_date = {}\n",
    "        for file in os.listdir(tweet_dir):\n",
    "            file_path = os.path.join(tweet_dir, file)\n",
    "            if os.path.isfile(file_path):\n",
    "                tweets_with_dates = parse_tweet_file(file_path, start_date, end_date)\n",
    "                for tweet_text, date_key in tweets_with_dates:\n",
    "                    if date_key not in tweets_by_date:\n",
    "                        tweets_by_date[date_key] = []\n",
    "                    tweets_by_date[date_key].append(tweet_text)\n",
    "        if not tweets_by_date:\n",
    "            continue\n",
    "\n",
    "        daily_sentiments = {}\n",
    "        for date, tweets in tweets_by_date.items():\n",
    "            daily_compound_scores = [sia.polarity_scores(tweet)['compound'] for tweet in tweets]\n",
    "            if daily_compound_scores:\n",
    "                daily_sentiments[date] = np.mean(daily_compound_scores)\n",
    "\n",
    "        sorted_dates = sorted(ticker_prices.keys())\n",
    "        prev_sentiment = None\n",
    "        prev_price = None\n",
    "        moving_avg_window = 5\n",
    "        for i, date_today in enumerate(sorted_dates[:-1]):\n",
    "            date_tomorrow = sorted_dates[i + 1]\n",
    "            if date_today in daily_sentiments and date_today in ticker_prices:\n",
    "                # Use features up to date_today to predict price movement on date_tomorrow\n",
    "                sentiment_score = daily_sentiments[date_today]\n",
    "                price_today = ticker_prices[date_today]\n",
    "                volume_today = ticker_volumes[date_today]\n",
    "                \n",
    "                # Label is based on price change from date_today to date_tomorrow\n",
    "                price_tomorrow = ticker_prices[date_tomorrow]\n",
    "                label = 1 if price_tomorrow > price_today else 0\n",
    "                \n",
    "                # Features should not use data from date_tomorrow or later\n",
    "                if i >= moving_avg_window:\n",
    "                    moving_avg = np.mean([ticker_prices[sorted_dates[j]] for j in range(i - moving_avg_window, i)])\n",
    "                else:\n",
    "                    moving_avg = np.mean([ticker_prices[sorted_dates[j]] for j in range(i)])\n",
    "\n",
    "                next_day = date_today + datetime.timedelta(days=1)\n",
    "                if next_day in ticker_prices:\n",
    "                    price_next = ticker_prices[next_day]\n",
    "                    price_diff = price_next - price_today\n",
    "                    label = 1 if price_diff > 0 else 0\n",
    "                    sentiment_change = sentiment_score - prev_sentiment if prev_sentiment is not None else 0\n",
    "                    price_change = price_today - prev_price if prev_price is not None else 0\n",
    "                    moving_avg = np.mean([ticker_prices[sorted_dates[j]] for j in range(max(0, i - moving_avg_window + 1), i + 1)])\n",
    "                    day_of_week = date_today.weekday()\n",
    "\n",
    "                    sentiments.append(sentiment_score)\n",
    "                    sentiment_changes.append(sentiment_change)\n",
    "                    price_changes.append(price_change)\n",
    "                    moving_averages.append(moving_avg)\n",
    "                    volumes.append(volume_today)\n",
    "                    days_of_week.append(day_of_week)\n",
    "                    labels.append(label)\n",
    "\n",
    "                    prev_sentiment = sentiment_score\n",
    "                    prev_price = price_today\n",
    "\n",
    "    return sentiments, price_changes, labels\n",
    "\n",
    "\n",
    "\n",
    "tweet_root_dir = '/home/sigurds/ikt450/Project/Data/stocknet-dataset-master/tweet/preprocessed/'\n",
    "price_root_dir = '/home/sigurds/ikt450/Project/Data/stocknet-dataset-master/price/preprocessed/'\n",
    "\n",
    "# Define new date ranges\n",
    "\"\"\"\n",
    "train_start_date = datetime.date(2014, 1, 1)\n",
    "train_end_date = datetime.date(2015, 6, 30)\n",
    "test_start_date = datetime.date(2015, 7, 1)\n",
    "test_end_date = datetime.date(2016, 1, 1)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "train_start_date = datetime.date(2014, 1, 1)\n",
    "train_end_date = datetime.date(2016, 1, 1)\n",
    "test_start_date = datetime.date(2014, 1, 1)\n",
    "test_end_date = datetime.date(2016, 1, 1)\n",
    "\n",
    "\n",
    "\n",
    "# Get all available tickers from the tweet data directory\n",
    "all_tickers = [ticker for ticker in os.listdir(tweet_root_dir) if os.path.isdir(os.path.join(tweet_root_dir, ticker))]\n",
    "\n",
    "# Split the tickers into training and testing sets with no overlap\n",
    "train_tickers, test_tickers = train_test_split(all_tickers, test_size=0.2, random_state=42)\n",
    "\n",
    "# Verify that there is no overlap between train_tickers and test_tickers\n",
    "assert set(train_tickers).isdisjoint(set(test_tickers)), \"Training and testing tickers overlap!\"\n",
    "\n",
    "# Load training data from train tickers\n",
    "(sentiments_train, price_changes_train,\n",
    " labels_train) = load_data_with_sentiment(\n",
    "    tweet_root_dir, price_root_dir, train_start_date, train_end_date, train_tickers)\n",
    "\n",
    "# Load testing data from test tickers\n",
    "(sentiments_test,  price_changes_test,\n",
    " labels_test) = load_data_with_sentiment(\n",
    "    tweet_root_dir, price_root_dir, test_start_date, test_end_date, test_tickers)\n",
    "\n",
    "if not sentiments_train or not sentiments_test:\n",
    "    print(\"No data was loaded. Please check your data files and parsing functions.\")\n",
    "else:\n",
    "    # Convert lists to NumPy arrays\n",
    "    sentiments_train = np.array(sentiments_train)\n",
    "    sentiment_changes_train = np.array(sentiment_changes_train)\n",
    "    price_changes_train = np.array(price_changes_train)\n",
    "    moving_averages_train = np.array(moving_averages_train)\n",
    "    volumes_train = np.array(volumes_train)\n",
    "    days_of_week_train = np.array(days_of_week_train)\n",
    "    labels_train = np.array(labels_train)\n",
    "\n",
    "    sentiments_test = np.array(sentiments_test)\n",
    "    sentiment_changes_test = np.array(sentiment_changes_test)\n",
    "    price_changes_test = np.array(price_changes_test)\n",
    "    moving_averages_test = np.array(moving_averages_test)\n",
    "    volumes_test = np.array(volumes_test)\n",
    "    days_of_week_test = np.array(days_of_week_test)\n",
    "    labels_test = np.array(labels_test)\n",
    "\n",
    "    # Stack features\n",
    "    x_train = np.column_stack((sentiments_train,  price_changes_train,\n",
    "                              ))\n",
    "    x_test = np.column_stack((sentiments_test,  price_changes_test,\n",
    "                              ))\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    x_train = scaler.fit_transform(x_train.reshape(-1, x_train.shape[-1])).reshape(x_train.shape)\n",
    "    x_test = scaler.transform(x_test.reshape(-1, x_test.shape[-1])).reshape(x_test.shape)\n",
    "\n",
    "    # Reshape data\n",
    "    x_train = x_train.reshape((x_train.shape[0], 1, x_train.shape[1]))\n",
    "    x_test = x_test.reshape((x_test.shape[0], 1, x_test.shape[1]))\n",
    "\n",
    "\n",
    "    # Create TensorFlow datasets\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((x_train, labels_train))\n",
    "    train_dataset = train_dataset.shuffle(1024).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((x_test, labels_test))\n",
    "    test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    # Build and compile the model\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(1, 2)),\n",
    "        layers.Bidirectional(tf.keras.layers.LSTM(units=64)),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(16, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "history = model.fit(train_dataset, epochs=50, validation_data=test_dataset)\n",
    "\n",
    "# Evaluate model on test data\n",
    "y_pred_prob = model.predict(x_test).flatten()\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "precision = precision_score(labels_test, y_pred)\n",
    "recall = recall_score(labels_test, y_pred)\n",
    "f1 = f1_score(labels_test, y_pred)\n",
    "accuracy = accuracy_score(labels_test, y_pred)\n",
    "\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Plotting test accuracy over epochs\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ffc83dac-ea05-45b6-a0cf-272266e13f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "plt.savefig('BIdirectional_ACC_3_inputs.pdf', format='pdf')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48193d2f-0ef6-48f4-baa0-6bf987e0de5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71b28335-39a1-463f-a0e2-7310894f4537",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "385/385 [==============================] - 4s 5ms/step - loss: 1.1449 - accuracy: 0.5879 - val_loss: 0.9310 - val_accuracy: 0.6482\n",
      "Epoch 2/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.8514 - accuracy: 0.6299 - val_loss: 0.7604 - val_accuracy: 0.6530\n",
      "Epoch 3/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.7244 - accuracy: 0.6469 - val_loss: 0.6826 - val_accuracy: 0.6533\n",
      "Epoch 4/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.6708 - accuracy: 0.6509 - val_loss: 0.6529 - val_accuracy: 0.6540\n",
      "Epoch 5/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.6501 - accuracy: 0.6522 - val_loss: 0.6375 - val_accuracy: 0.6622\n",
      "Epoch 6/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.6417 - accuracy: 0.6573 - val_loss: 0.6321 - val_accuracy: 0.6602\n",
      "Epoch 7/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.6386 - accuracy: 0.6533 - val_loss: 0.6306 - val_accuracy: 0.6619\n",
      "Epoch 8/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.6358 - accuracy: 0.6568 - val_loss: 0.6303 - val_accuracy: 0.6636\n",
      "Epoch 9/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.6347 - accuracy: 0.6551 - val_loss: 0.6313 - val_accuracy: 0.6632\n",
      "Epoch 10/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.6362 - accuracy: 0.6566 - val_loss: 0.6310 - val_accuracy: 0.6598\n",
      "Epoch 11/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.6343 - accuracy: 0.6616 - val_loss: 0.6237 - val_accuracy: 0.6660\n",
      "Epoch 12/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.6306 - accuracy: 0.6620 - val_loss: 0.6252 - val_accuracy: 0.6646\n",
      "Epoch 13/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.6314 - accuracy: 0.6620 - val_loss: 0.6205 - val_accuracy: 0.6663\n",
      "Epoch 14/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.6281 - accuracy: 0.6605 - val_loss: 0.6216 - val_accuracy: 0.6725\n",
      "Epoch 15/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.6295 - accuracy: 0.6657 - val_loss: 0.6177 - val_accuracy: 0.6769\n",
      "Epoch 16/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.6263 - accuracy: 0.6641 - val_loss: 0.6221 - val_accuracy: 0.6756\n",
      "Epoch 17/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.6217 - accuracy: 0.6695 - val_loss: 0.6227 - val_accuracy: 0.6807\n",
      "Epoch 18/50\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.6204 - accuracy: 0.6755 - val_loss: 0.6217 - val_accuracy: 0.6838\n",
      "Epoch 19/50\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.6142 - accuracy: 0.6775 - val_loss: 0.6238 - val_accuracy: 0.6964\n",
      "Epoch 20/50\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.6109 - accuracy: 0.6803 - val_loss: 0.6200 - val_accuracy: 0.6954\n",
      "Epoch 21/50\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.6111 - accuracy: 0.6793 - val_loss: 0.6277 - val_accuracy: 0.7009\n",
      "Epoch 22/50\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.6073 - accuracy: 0.6847 - val_loss: 0.6353 - val_accuracy: 0.6933\n",
      "Epoch 23/50\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.6074 - accuracy: 0.6823 - val_loss: 0.6342 - val_accuracy: 0.7063\n",
      "Epoch 24/50\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.6041 - accuracy: 0.6863 - val_loss: 0.6188 - val_accuracy: 0.6988\n",
      "Epoch 25/50\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.6022 - accuracy: 0.6901 - val_loss: 0.6150 - val_accuracy: 0.7128\n",
      "Epoch 26/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.6005 - accuracy: 0.6896 - val_loss: 0.6274 - val_accuracy: 0.7156\n",
      "Epoch 27/50\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5985 - accuracy: 0.6893 - val_loss: 0.6296 - val_accuracy: 0.6950\n",
      "Epoch 28/50\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.6034 - accuracy: 0.6905 - val_loss: 0.6220 - val_accuracy: 0.7091\n",
      "Epoch 29/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.5994 - accuracy: 0.6937 - val_loss: 0.6294 - val_accuracy: 0.7060\n",
      "Epoch 30/50\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5992 - accuracy: 0.6919 - val_loss: 0.6350 - val_accuracy: 0.7128\n",
      "Epoch 31/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.5972 - accuracy: 0.6901 - val_loss: 0.6244 - val_accuracy: 0.7070\n",
      "Epoch 32/50\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5990 - accuracy: 0.6912 - val_loss: 0.6249 - val_accuracy: 0.7067\n",
      "Epoch 33/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.5973 - accuracy: 0.6949 - val_loss: 0.6244 - val_accuracy: 0.7149\n",
      "Epoch 34/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.6004 - accuracy: 0.6945 - val_loss: 0.6399 - val_accuracy: 0.7015\n",
      "Epoch 35/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.5981 - accuracy: 0.6919 - val_loss: 0.6353 - val_accuracy: 0.7074\n",
      "Epoch 36/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.5975 - accuracy: 0.6934 - val_loss: 0.6200 - val_accuracy: 0.7015\n",
      "Epoch 37/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.5973 - accuracy: 0.6946 - val_loss: 0.6207 - val_accuracy: 0.7142\n",
      "Epoch 38/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.5955 - accuracy: 0.6958 - val_loss: 0.6379 - val_accuracy: 0.7156\n",
      "Epoch 39/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.5985 - accuracy: 0.6966 - val_loss: 0.6253 - val_accuracy: 0.7121\n",
      "Epoch 40/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.5971 - accuracy: 0.6998 - val_loss: 0.6196 - val_accuracy: 0.7060\n",
      "Epoch 41/50\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5975 - accuracy: 0.6901 - val_loss: 0.6305 - val_accuracy: 0.7190\n",
      "Epoch 42/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.6003 - accuracy: 0.6949 - val_loss: 0.6122 - val_accuracy: 0.7104\n",
      "Epoch 43/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.5960 - accuracy: 0.6932 - val_loss: 0.6080 - val_accuracy: 0.7043\n",
      "Epoch 44/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.5948 - accuracy: 0.6964 - val_loss: 0.6272 - val_accuracy: 0.7135\n",
      "Epoch 45/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.5959 - accuracy: 0.6977 - val_loss: 0.6141 - val_accuracy: 0.7132\n",
      "Epoch 46/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.5964 - accuracy: 0.6948 - val_loss: 0.6300 - val_accuracy: 0.7108\n",
      "Epoch 47/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.5947 - accuracy: 0.6986 - val_loss: 0.6235 - val_accuracy: 0.7111\n",
      "Epoch 48/50\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5977 - accuracy: 0.6936 - val_loss: 0.6166 - val_accuracy: 0.7152\n",
      "Epoch 49/50\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5931 - accuracy: 0.6953 - val_loss: 0.6190 - val_accuracy: 0.7132\n",
      "Epoch 50/50\n",
      "385/385 [==============================] - 2s 5ms/step - loss: 0.5944 - accuracy: 0.6974 - val_loss: 0.6250 - val_accuracy: 0.7169\n",
      "92/92 [==============================] - 0s 1ms/step\n",
      "Precision: 0.69\n",
      "Recall: 0.78\n",
      "F1 Score: 0.73\n",
      "Accuracy: 71.69%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x79f73228b9d0>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import pytz\n",
    "from dateutil import parser\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "def parse_tweet_file(file_path, start_date, end_date):\n",
    "    tweets = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                tweet_data = json.loads(line)\n",
    "                tweet_text = \" \".join(tweet_data['text']) if isinstance(tweet_data['text'], list) else tweet_data['text']\n",
    "                tweet_time = parser.parse(tweet_data['created_at'])\n",
    "                tweet_time = tweet_time.astimezone(pytz.timezone('US/Eastern'))\n",
    "                date_key = tweet_time.date()\n",
    "                if start_date <= date_key <= end_date:\n",
    "                    tweets.append((tweet_text, date_key))\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "    return tweets\n",
    "\n",
    "def parse_price_file(file_path, start_date, end_date):\n",
    "    prices = {}\n",
    "    volumes = {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            fields = line.strip().split('\\t')\n",
    "            if len(fields) < 6:\n",
    "                continue\n",
    "            date_str = fields[0]\n",
    "            try:\n",
    "                price_time = datetime.datetime.strptime(date_str, '%Y-%m-%d')\n",
    "                date_key = price_time.date()\n",
    "                if start_date <= date_key <= end_date:\n",
    "                    close_price_str = fields[4]\n",
    "                    volume_str = fields[5]\n",
    "                    close_price = float(close_price_str)\n",
    "                    volume = float(volume_str)\n",
    "                    prices[date_key] = close_price\n",
    "                    volumes[date_key] = volume\n",
    "            except ValueError:\n",
    "                continue\n",
    "    return prices, volumes\n",
    "\n",
    "\n",
    "#function to load sentiments and process the information so RNN can get different features out of it\n",
    "def load_data_with_sentiment(tweet_root_dir, price_root_dir, start_date, end_date, tickers):\n",
    "    sentiments = []\n",
    "    labels = []\n",
    "    sentiment_changes = []\n",
    "    price_changes = []\n",
    "    moving_averages = []\n",
    "    volumes = []\n",
    "    days_of_week = []\n",
    "    month_average = []\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "    for ticker in tickers:\n",
    "        tweet_dir = os.path.join(tweet_root_dir, ticker)\n",
    "        price_file = os.path.join(price_root_dir, f\"{ticker}.txt\")\n",
    "\n",
    "        if not os.path.isdir(tweet_dir) or not os.path.isfile(price_file):\n",
    "            continue\n",
    "\n",
    "        ticker_prices, ticker_volumes = parse_price_file(price_file, start_date, end_date)\n",
    "        if not ticker_prices:\n",
    "            continue\n",
    "\n",
    "        tweets_by_date = {}\n",
    "        for file in os.listdir(tweet_dir):\n",
    "            file_path = os.path.join(tweet_dir, file)\n",
    "            if os.path.isfile(file_path):\n",
    "                tweets_with_dates = parse_tweet_file(file_path, start_date, end_date)\n",
    "                for tweet_text, date_key in tweets_with_dates:\n",
    "                    if date_key not in tweets_by_date:\n",
    "                        tweets_by_date[date_key] = []\n",
    "                    tweets_by_date[date_key].append(tweet_text)\n",
    "        if not tweets_by_date:\n",
    "            continue\n",
    "\n",
    "        daily_sentiments = {}\n",
    "        for date, tweets in tweets_by_date.items():\n",
    "            daily_compound_scores = [sia.polarity_scores(tweet)['compound'] for tweet in tweets]\n",
    "            if daily_compound_scores:\n",
    "                daily_sentiments[date] = np.mean(daily_compound_scores)\n",
    "\n",
    "        sorted_dates = sorted(ticker_prices.keys())\n",
    "        prev_sentiment = None\n",
    "        prev_price = None\n",
    "        moving_avg_window = 5\n",
    "        for i, date_today in enumerate(sorted_dates[:-1]):\n",
    "            date_tomorrow = sorted_dates[i + 1]\n",
    "            if date_today in daily_sentiments and date_today in ticker_prices:\n",
    "                # Use features up to date_today to predict price movement on date_tomorrow\n",
    "                sentiment_score = daily_sentiments[date_today]\n",
    "                price_today = ticker_prices[date_today]\n",
    "                volume_today = ticker_volumes[date_today]\n",
    "                \n",
    "                # Label is based on price change from date_today to date_tomorrow\n",
    "                price_tomorrow = ticker_prices[date_tomorrow]\n",
    "                label = 1 if price_tomorrow > price_today else 0\n",
    "                \n",
    "                # Features should not use data from date_tomorrow or later\n",
    "                if i >= moving_avg_window:\n",
    "                    moving_avg = np.mean([ticker_prices[sorted_dates[j]] for j in range(i - moving_avg_window, i)])\n",
    "                else:\n",
    "                    moving_avg = np.mean([ticker_prices[sorted_dates[j]] for j in range(i)])\n",
    "\n",
    "                next_day = date_today + datetime.timedelta(days=1)\n",
    "                if next_day in ticker_prices:\n",
    "                    price_next = ticker_prices[next_day]\n",
    "                    price_diff = price_next - price_today\n",
    "                    label = 1 if price_diff > 0 else 0\n",
    "                    sentiment_change = sentiment_score - prev_sentiment if prev_sentiment is not None else 0\n",
    "                    price_change = price_today - prev_price if prev_price is not None else 0\n",
    "                    moving_avg = np.mean([ticker_prices[sorted_dates[j]] for j in range(max(0, i - moving_avg_window + 1), i + 1)])\n",
    "                    day_of_week = date_today.weekday()\n",
    "\n",
    "                    sentiments.append(sentiment_score)\n",
    "                    sentiment_changes.append(sentiment_change)\n",
    "                    price_changes.append(price_change)\n",
    "                    moving_averages.append(moving_avg)\n",
    "                    volumes.append(volume_today)\n",
    "                    days_of_week.append(day_of_week)\n",
    "                    labels.append(label)\n",
    "\n",
    "                    prev_sentiment = sentiment_score\n",
    "                    prev_price = price_today\n",
    "\n",
    "    return sentiments, sentiment_changes, price_changes, moving_averages, volumes, days_of_week, labels\n",
    "\n",
    "\n",
    "\n",
    "tweet_root_dir = '/home/sigurds/ikt450/Project/Data/stocknet-dataset-master/tweet/preprocessed/'\n",
    "price_root_dir = '/home/sigurds/ikt450/Project/Data/stocknet-dataset-master/price/preprocessed/'\n",
    "\n",
    "# Define new date ranges\n",
    "\"\"\"\n",
    "train_start_date = datetime.date(2014, 1, 1)\n",
    "train_end_date = datetime.date(2015, 6, 30)\n",
    "test_start_date = datetime.date(2015, 7, 1)\n",
    "test_end_date = datetime.date(2016, 1, 1)\n",
    "\n",
    "\"\"\"\n",
    "train_start_date = datetime.date(2014, 1, 1)\n",
    "train_end_date = datetime.date(2016, 1, 1)\n",
    "test_start_date = datetime.date(2014, 1, 1)\n",
    "test_end_date = datetime.date(2016, 1, 1)\n",
    "\n",
    "\n",
    "\n",
    "# Get all available tickers from the tweet data directory\n",
    "all_tickers = [ticker for ticker in os.listdir(tweet_root_dir) if os.path.isdir(os.path.join(tweet_root_dir, ticker))]\n",
    "\n",
    "# Split the tickers into training and testing sets with no overlap\n",
    "train_tickers, test_tickers = train_test_split(all_tickers, test_size=0.2, random_state=42)\n",
    "\n",
    "# Verify that there is no overlap between train_tickers and test_tickers\n",
    "assert set(train_tickers).isdisjoint(set(test_tickers)), \"Training and testing tickers overlap!\"\n",
    "\n",
    "# Load training data from train tickers\n",
    "(sentiments_train, sentiment_changes_train, price_changes_train,\n",
    " moving_averages_train, volumes_train, days_of_week_train, labels_train) = load_data_with_sentiment(\n",
    "    tweet_root_dir, price_root_dir, train_start_date, train_end_date, train_tickers)\n",
    "\n",
    "# Load testing data from test tickers\n",
    "(sentiments_test, sentiment_changes_test, price_changes_test,\n",
    " moving_averages_test, volumes_test, days_of_week_test, labels_test) = load_data_with_sentiment(\n",
    "    tweet_root_dir, price_root_dir, test_start_date, test_end_date, test_tickers)\n",
    "\n",
    "if not sentiments_train or not sentiments_test:\n",
    "    print(\"No data was loaded. Please check your data files and parsing functions.\")\n",
    "else:\n",
    "    # Convert lists to NumPy arrays\n",
    "    sentiments_train = np.array(sentiments_train)\n",
    "    sentiment_changes_train = np.array(sentiment_changes_train)\n",
    "    price_changes_train = np.array(price_changes_train)\n",
    "    moving_averages_train = np.array(moving_averages_train)\n",
    "    volumes_train = np.array(volumes_train)\n",
    "    days_of_week_train = np.array(days_of_week_train)\n",
    "    labels_train = np.array(labels_train)\n",
    "\n",
    "    sentiments_test = np.array(sentiments_test)\n",
    "    sentiment_changes_test = np.array(sentiment_changes_test)\n",
    "    price_changes_test = np.array(price_changes_test)\n",
    "    moving_averages_test = np.array(moving_averages_test)\n",
    "    volumes_test = np.array(volumes_test)\n",
    "    days_of_week_test = np.array(days_of_week_test)\n",
    "    labels_test = np.array(labels_test)\n",
    "\n",
    "    # Stack features\n",
    "    x_train = np.column_stack((sentiments_train, sentiment_changes_train, price_changes_train,\n",
    "                               moving_averages_train, volumes_train, days_of_week_train))\n",
    "    x_test = np.column_stack((sentiments_test, sentiment_changes_test, price_changes_test,\n",
    "                              moving_averages_test, volumes_test, days_of_week_test))\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    x_train = scaler.fit_transform(x_train.reshape(-1, x_train.shape[-1])).reshape(x_train.shape)\n",
    "    x_test = scaler.transform(x_test.reshape(-1, x_test.shape[-1])).reshape(x_test.shape)\n",
    "\n",
    "    # Reshape data\n",
    "    x_train = x_train.reshape((x_train.shape[0], 1, x_train.shape[1]))\n",
    "    x_test = x_test.reshape((x_test.shape[0], 1, x_test.shape[1]))\n",
    "\n",
    "\n",
    "    # Create TensorFlow datasets\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((x_train, labels_train))\n",
    "    train_dataset = train_dataset.shuffle(1024).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((x_test, labels_test))\n",
    "    test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "       # Build and compile the model with Simple RNN\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(1, 6)),  # Input shape adjusted to (time_steps, features)\n",
    "        layers.SimpleRNN(64, return_sequences=False),  # SimpleRNN with 64 units\n",
    "        layers.Dropout(0.3),  # Dropout to prevent overfitting\n",
    "        layers.Dense(32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),  # Dense layer with ReLU activation\n",
    "        layers.BatchNormalization(),  # Batch normalization for stable training\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(16, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "    ])\n",
    "\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_dataset, epochs=50, validation_data=test_dataset)\n",
    "\n",
    "# Evaluate model on test data\n",
    "y_pred_prob = model.predict(x_test).flatten()\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "precision = precision_score(labels_test, y_pred)\n",
    "recall = recall_score(labels_test, y_pred)\n",
    "f1 = f1_score(labels_test, y_pred)\n",
    "accuracy = accuracy_score(labels_test, y_pred)\n",
    "\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Plotting test accuracy over epochs\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d9d39b-7b3e-447b-82b2-b39f631714a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.savefig('SimpleRNN_ACC_FULLDATE.pdf', format='pdf')\n",
    "plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
